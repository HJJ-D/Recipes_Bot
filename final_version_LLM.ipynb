{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading RAG database set up LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\lab-mushroom-chatbot\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "import gradio as gr\n",
    "import google.generativeai as genai\n",
    "from chromadb.utils import embedding_functions\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "# Load HF token and login if necessary\n",
    "# Method 1: Set your HF token as an environment variable\n",
    "# You can set it in your system environment variables or in a .env file\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import google.generativeai as genai\n",
    "\n",
    "hf_token = os.getenv('HF_TOKEN')\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "\n",
    "api_key = os.getenv('GENAI_API_KEY')\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash-lite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded datasetÔºö 3993\n"
     ]
    }
   ],
   "source": [
    "db_path = r\"vector_new_db/recipes\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=db_path)\n",
    "\n",
    "embedder = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"BAAI/bge-m3\"\n",
    ")\n",
    "\n",
    "collection = chroma_client.get_collection(\"recipes\")\n",
    "\n",
    "print(\"Successfully loaded datasetÔºö\", collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting with Gemini and fine turning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15392\\616999502.py:204: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chef ü§ñ\", height=500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://bc8f48f3deeb10c260.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bc8f48f3deeb10c260.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG context for recipe generation: Recipe 1: Spicy Minced Pork with Green Beans (Spicy & Aromatic, Medium, 15 min)\n",
      "Recipe Name: Spicy Minced Pork with Green Beans\n",
      "Ingredients: Green beans; Minced pork; Chili; Garlic; Ginger; Sichuan pepper\n",
      "Flavor: Spicy & Aromatic\n",
      "\n",
      "\n",
      "Recipe 2: Simplified Sichuan Poached Sliced Meat (Spicy & Bold, Medium, 30 min)\n",
      "Recipe Name: Simplified Sichuan Poached Sliced Meat\n",
      "Ingredients: Pork or beef; Chili; Pepper; Bean paste; Garlic; Ginger; Sugar; Starch\n",
      "Flavor: Spicy & Bold\n",
      "\n",
      "\n",
      "Recipe 3: Steamed Sliced Pork with Chinese Cabbage (Savory, Umami (Soy Sauce/Pork), Tender, Soft, Easy, 30 - 35 Minutes)\n",
      "Recipe Name: Steamed Sliced Pork with Chinese Cabbage\n",
      "Ingredients: Chinese cabbage (Wa Wa Cai); Pork belly (Wu Hua Rou); Ginger; Garlic; Salt; Light soy sauce; Starch\n",
      "Flavor: Savory, Umami (Soy Sauce/Pork), Tender, Soft\n",
      "\n",
      "Using RAG context for recipe generation.\n",
      "RAG context for recipe generation: Recipe 1: Recipes_name (Flavor, Difficulty, Estimated Cooking Time)\n",
      "Recipe Name: Recipes_name\n",
      "Ingredients: Ingredients\n",
      "Flavor: Flavor\n",
      "\n",
      "\n",
      "Recipe 2: Chinese Savory Pancake (Crunchy & Flavorful, Medium, 40 min)\n",
      "Recipe Name: Chinese Savory Pancake\n",
      "Ingredients: Flour; Oil; Soybean paste; Onion; Garlic; Sesame\n",
      "Flavor: Crunchy & Flavorful\n",
      "\n",
      "\n",
      "Recipe 3: Shanghai Hand-Torn Cabbage (Salty (from curing), Savory, Simple, Slightly Spicy, Medium, 20 - 25 Minutes (Excludes curing time))\n",
      "Recipe Name: Shanghai Hand-Torn Cabbage\n",
      "Ingredients: Shanghai bok choy; Salt; Millet chili; White button mushrooms; Edamame (Green soybeans); Ginger\n",
      "Flavor: Salty (from curing), Savory, Simple, Slightly Spicy\n",
      "\n",
      "Using RAG context for recipe generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "banned_inputs = [\"poison\", \"bleach\", \"uncooked chicken\", \"alcohol for children\"]\n",
    "unsafe_outputs = [\"eat raw\", \"toxic\", \"unsafe\"]\n",
    "\n",
    "def check_input_safe(text):\n",
    "    return not any(bad in text.lower() for bad in banned_inputs)\n",
    "\n",
    "def sanitize_output(text):\n",
    "    if any(p in text.lower() for p in unsafe_outputs):\n",
    "        return \"‚ö†Ô∏è Warning: Some parts may be unsafe. Please cook ingredients thoroughly.\"\n",
    "    return text\n",
    "\n",
    "\n",
    "# ------------------ Loading memory from Gradio history ------------------\n",
    "def get_memory_from_history(history, max_turns=3):\n",
    "    if not history:\n",
    "        return \"No previous conversation.\"\n",
    "    \n",
    "    recent_history = history[-max_turns:] if len(history) > max_turns else history\n",
    "    \n",
    "    memory_text = \"\\n\".join([\n",
    "        f\"User: {turn[0]}\\nAssistant: {turn[1]}\"\n",
    "        for turn in recent_history\n",
    "    ])\n",
    "    return memory_text\n",
    "\n",
    "\n",
    "def should_use_rag(query):\n",
    "    keywords = [\"i have\", \"recipe\", \"ingredients\", \"make with\", \"what can i cook\", \n",
    "                \"dish\", \"food\", \"cook\", \"prepare\", \"meal\", \"I have\"]\n",
    "    return any(kw in query.lower() for kw in keywords)\n",
    "\n",
    "\n",
    "# ------------------ RAG retrival function ------------------\n",
    "def retrieve_recipes(query, top_k=3):\n",
    "    try:\n",
    "        # Ê≠•È™§ 1: ËÆæËÆ°ÂÖ≥ÈîÆËØçÊèêÂèñÁöÑ Prompt\n",
    "        extraction_prompt = f\"\"\"\n",
    "        Extract the key food-related entities from the following user query. \n",
    "        Focus ONLY on ingredients, cuisine type, flavor, cooking method, or dish name.\n",
    "        Return the entities as a comma-separated list.\n",
    "        \n",
    "        Query: \"{query}\"\n",
    "        \n",
    "        Keywords:\n",
    "        \"\"\"\n",
    "\n",
    "        # Ê≠•È™§ 2: Ë∞ÉÁî®Ê®°ÂûãËøõË°åÊèêÂèñ\n",
    "        # .text ÊòØ‰∏∫‰∫ÜËé∑Âèñ generate_content ËøîÂõûÁöÑ Part ÂØπË±°ÁöÑÊñáÊú¨ÂÜÖÂÆπ\n",
    "        extracted_keywords_response = model.generate_content(extraction_prompt)\n",
    "        extracted_keywords = extracted_keywords_response.text.strip()\n",
    "\n",
    "        # Â¶ÇÊûúÊ≤°ÊúâÊèêÂèñÂà∞ÂÖ≥ÈîÆËØçÔºå‰∏∫‰∫Ü‰øùÈô©Ëµ∑ËßÅÔºå‰ªçÁÑ∂‰ΩøÁî®ÂéüÂßãÊü•ËØ¢\n",
    "        if not extracted_keywords:\n",
    "            search_query = query\n",
    "        else:\n",
    "            search_query = extracted_keywords\n",
    "        \n",
    "        print(f\"Original Query: '{query}' -> Search Query: '{search_query}'\")\n",
    "\n",
    "        # Ê≠•È™§ 3: ‰ΩøÁî®ÊèêÁ∫ØÂêéÁöÑÂÖ≥ÈîÆËØçËøõË°åÂêëÈáèÂµåÂÖ•ÂíåÊ£ÄÁ¥¢\n",
    "        query_emb = embedder([search_query])[0]\n",
    "        results = collection.query(\n",
    "            query_embeddings=[query_emb], \n",
    "            n_results=top_k\n",
    "        )\n",
    "        \n",
    "        retrieved_docs = []\n",
    "        for i in range(top_k):\n",
    "            meta = results[\"metadatas\"][0][i]\n",
    "            doc = results[\"documents\"][0][i]\n",
    "            retrieved_docs.append(\n",
    "                f\"Recipe {i+1}: {meta['Recipes_name']} ({meta['Flavor']}, {meta['Difficulty']}, {meta['Estimated Cooking Time']})\\n{doc}\"\n",
    "            )\n",
    "        return \"\\n\\n\".join(retrieved_docs)\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def chat_with_memory_stream(message, history):\n",
    "    # 1. safty check\n",
    "    if not check_input_safe(message):\n",
    "        history.append([message, \"‚ö†Ô∏è Sorry, that recipe request might be unsafe.\"])\n",
    "        yield history\n",
    "        return\n",
    "    \n",
    "    # 2. extract memory\n",
    "    memory_context = get_memory_from_history(history, max_turns=10)\n",
    "    \n",
    "    # 3. check RAG retrival\n",
    "    use_rag = should_use_rag(message)\n",
    "    rag_context = \"\"\n",
    "    \n",
    "    if use_rag:\n",
    "        rag_context = retrieve_recipes(message, top_k=3)\n",
    "    \n",
    "    # 4. create prompt\n",
    "    if use_rag and rag_context:\n",
    "        prompt = f\"\"\"\n",
    "You are a warm and skilled Chinese cuisine assistant.\n",
    "\n",
    "Always try to guide the conversation naturally toward **Chinese cooking** ‚Äî\n",
    "you may explain differences or suggest a Chinese-style version of the dish if the user asks about other cuisines.\n",
    "Do not refuse directly; instead, gently introduce Chinese dishes or cooking principles.\n",
    "\n",
    "Recent conversation:\n",
    "{memory_context}\n",
    "\n",
    "User query:\n",
    "{message}\n",
    "\n",
    "Here are some related recipes from the database:\n",
    "{rag_context}\n",
    "\n",
    "Please take the recipes I‚Äôve provided to you, and‚Äîbased on the user‚Äôs needs as well as your understanding of these dishes‚Äîgenerate detailed recipe information.\n",
    "Please describe the recipe steps clearly in English.\n",
    "\n",
    "Please respond naturally and helpfully in English.\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "You are an expert in **Chinese cuisine**.\n",
    "\n",
    "Even if the user asks about other cuisines, \n",
    "respond by gently introducing relevant Chinese dishes, flavors, or adaptations.\n",
    "\n",
    "Recent conversation:\n",
    "{memory_context}\n",
    "\n",
    "User query:\n",
    "{message}\n",
    "\n",
    "Please respond conversationally and helpfully in English.\"\"\"\n",
    "    \n",
    "    # 5. floating Gemini\n",
    "    history.append([message, \"\"])  \n",
    "    \n",
    "    try:\n",
    "        response_text = \"\"\n",
    "        for chunk in model.generate_content(prompt, stream=True):\n",
    "            if chunk.text:\n",
    "                response_text += chunk.text\n",
    "                history[-1][1] = response_text\n",
    "                yield history\n",
    "        \n",
    "        # 6.output clean\n",
    "        sanitized_response = sanitize_output(response_text)\n",
    "        history[-1][1] = sanitized_response\n",
    "        yield history\n",
    "        \n",
    "    except Exception as e:\n",
    "        history[-1][1] = f\"‚ö†Ô∏è Error generating response: {str(e)}\"\n",
    "        yield history\n",
    "\n",
    "\n",
    "# ------------------ Generate Recipe button function ------------------\n",
    "def handle_generate_recipe(ingredients, taste, difficulty, time_limit, history):\n",
    "    \"\"\"\n",
    "    Handle Generate Recipe button click\n",
    "    Uses RAG retrieval first, then generates recipe response with context\n",
    "    \"\"\"\n",
    "    query = f\"Chinese recipe using: {ingredients}, flavor: {taste}, difficulty: {difficulty}\"\n",
    "    \n",
    "    rag_context = retrieve_recipes(query, top_k=3)\n",
    "    print(\"RAG context for recipe generation:\", rag_context)\n",
    "    \n",
    "    if rag_context:\n",
    "        print(\"Using RAG context for recipe generation.\")\n",
    "        prompt = f\"\"\"\n",
    "You are a warm and skilled Chinese cuisine assistant.\n",
    "\n",
    "User preferences:\n",
    "Ingredients: {ingredients}\n",
    "Flavor: {taste}\n",
    "Difficulty: {difficulty}\n",
    "Time limit: {time_limit} minutes\n",
    "\n",
    "Here are some relevant recipes from the database:\n",
    "{rag_context}\n",
    "\n",
    "Please take the recipes I‚Äôve provided to you, and‚Äîbased on the user‚Äôs needs as well as your understanding of these dishes‚Äîgenerate detailed recipe information.\n",
    "\n",
    "Please describe the recipe steps clearly in English.\n",
    "\"\"\"\n",
    "    else:\n",
    "        prompt = f\"\"\"\n",
    "You are a friendly and knowledgeable Chinese chef assistant.\n",
    "\n",
    "The user wants a recipe using:\n",
    "Ingredients: {ingredients}\n",
    "Flavor: {taste}\n",
    "Difficulty: {difficulty}\n",
    "Cooking time: {time_limit} minutes\n",
    "\n",
    "Please create a Chinese-style recipe and describe steps clearly in English.\n",
    "\"\"\"\n",
    "\n",
    "    history.append([query, \"\"])\n",
    "    try:\n",
    "        response_text = \"\"\n",
    "        for chunk in model.generate_content(prompt, stream=True):\n",
    "            if chunk.text:\n",
    "                response_text += chunk.text\n",
    "                history[-1][1] = response_text\n",
    "                yield history\n",
    "\n",
    "        sanitized_response = sanitize_output(response_text)\n",
    "        history[-1][1] = sanitized_response\n",
    "        yield history\n",
    "    except Exception as e:\n",
    "        history[-1][1] = f\"‚ö†Ô∏è Error generating recipe: {str(e)}\"\n",
    "        yield history\n",
    "\n",
    "\n",
    "# ------------------ clean chat ------------------\n",
    "def clear_chat():\n",
    "    return []\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# Gradio interface\n",
    "# ==========================================================\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"üç≥ Recipe Assistant\") as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üç≥ Recipe Assistant\n",
    "    *Your personal AI chef ‚Äî generate recipes and chat in one place!*\n",
    "    \n",
    "    ‚ú® Exploring anything you want here ‚ú®\n",
    "    \"\"\")\n",
    "    \n",
    "    chatbot = gr.Chatbot(label=\"Chef ü§ñ\", height=500)\n",
    "    \n",
    "    with gr.Accordion(\"üßÇ Recipe Preferences (click to expand)\", open=True):\n",
    "        with gr.Row():\n",
    "            ingredients = gr.Textbox(\n",
    "                label=\"Ingredients\", \n",
    "                placeholder=\"e.g., chicken, garlic, chili\", \n",
    "                lines=2\n",
    "            )\n",
    "            taste = gr.Dropdown(\n",
    "                label=\"Flavor\", \n",
    "                choices=[\"Spicy\", \"Sweet\", \"Savory\", \"Light\", \"Sour\"], \n",
    "                value=\"Savory\"\n",
    "            )\n",
    "        with gr.Row():\n",
    "            difficulty = gr.Radio(\n",
    "                label=\"Difficulty\", \n",
    "                choices=[\"Easy\", \"Medium\", \"Hard\"], \n",
    "                value=\"Medium\"\n",
    "            )\n",
    "            time_limit = gr.Slider(\n",
    "                label=\"Max Cooking Time (min)\", \n",
    "                minimum=5, \n",
    "                maximum=120, \n",
    "                value=30, \n",
    "                step=5\n",
    "            )\n",
    "        generate_btn = gr.Button(\"üç≤ Generate Recipe\")\n",
    "    \n",
    "    user_input = gr.Textbox(\n",
    "        label=\"üí¨ Ask the Chef\", \n",
    "        placeholder=\"e.g., Can I make it vegetarian? How to reduce cooking time?\"\n",
    "    )\n",
    "    clear_btn = gr.Button(\"üóëÔ∏è Clear Chat\")\n",
    "    \n",
    "\n",
    "    generate_btn.click(\n",
    "        handle_generate_recipe,\n",
    "        inputs=[ingredients, taste, difficulty, time_limit, chatbot],\n",
    "        outputs=chatbot\n",
    "    )\n",
    "    \n",
    "\n",
    "    user_input.submit(\n",
    "        chat_with_memory_stream,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=chatbot\n",
    "    ).then(\n",
    "        lambda: \"\",  \n",
    "        outputs=user_input\n",
    "    )\n",
    "    \n",
    "   \n",
    "    clear_btn.click(\n",
    "        clear_chat,\n",
    "        outputs=chatbot\n",
    "    )\n",
    "\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-mushroom-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
